"""
python kospeech1/bin/inference.py \
  --multi_model_paths normal.pt hearing.pt neuro.pt \
  --model_names normal hearing neuro \
  --paths \
    "normal /path/a.wav" \
    "hearing /path/b.wav" \
    "neuro:/path/c.wav"




python kospeech1/bin/inference.py \
  --multi_model_paths \
      outputs/normal/model.pt \
      outputs/hearing/model.pt \
      outputs/neuro/model.pt \
  --model_names normal hearing neuro \
  --vocab_path outputs/2-model/aihub_character_vocabs.csv \
  --device cuda:0 \
  --warmup

  
  python kospeech1/bin/inference.py \
  --multi_model_paths \
      outputs/2-model/model.pt \
      outputs/2-model/model-exear.pt \
  --model_names normal hearing \
  --vocab_path outputs/2-model/aihub_character_vocabs.csv \
  --device cuda:0 \
  --warmup

  
normal data/ID-02-27-N-BJJ-02-01-F-36-KK_ì¤‘ë³µ-4.wav
hearing data/ID-02-27-N-BJJ-02-01-F-36-KK_ì¤‘ë³µ-4.wav

> normal /path/to/normal_case.wav
> hearing /path/to/hearing_case.wav
> neuro /path/to/neuro_case.wav
> /path/to/anything.wav   # -> ê¸°ë³¸ ëª¨ë¸(normal) ì‚¬ìš©
> q



ì´ê±° ì—¬ì „íˆ ë™ì‘
python kospeech1/bin/inference.py \
  --multi_model_paths \
      outputs/2-model/model.pt \
      outputs/2-model/model-ear.pt \
  --model_names normal hearing \
  --vocab_path outputs/2-model/aihub_character_vocabs.csv \
  --device cuda:0 \
  --warmup



python kospeech1/bin/inference.py \
  --multi_model_paths \
      outputs/2-model/model.pt \
      outputs/2-model/model.pt \
  --model_names normal hearing \
  --adapter_paths none outputs/2-model/kor-bjj.pt \
  --vocab_path outputs/2-model/aihub_character_vocabs.csv \
  --device cuda:0 \
  --warmup


  

> normal /path/to/normal_case.wav
> hearing /path/to/hearing_case.wav
> neuro /path/to/neuro_case.wav
> /path/to/anything.wav   # -> ê¸°ë³¸ ëª¨ë¸(normal) ì‚¬ìš©
> q



"""








# -*- coding: utf-8 -*-
import argparse
import json
import sys
import time
from pathlib import Path
from typing import Optional, Sequence, Dict, Tuple, List

import numpy as np
import torch
import torchaudio
from torch import Tensor
from torch.serialization import add_safe_globals
from torch.nn.parallel.data_parallel import DataParallel

# ==== KoSpeech deps ====
from kospeech.vocabs.ksponspeech import KsponSpeechVocabulary
from kospeech.data.audio.core import load_audio
from kospeech.models import (
    SpeechTransformer, Jasper, DeepSpeech2, ListenAttendSpell, Conformer, MLPAdapter,
)

from tools import revise


# -----------------------------
# Audio front-end
# -----------------------------
def _load_pcm16le(path: str) -> np.ndarray:
    """RAW PCM 16-bit little-endian monoë¥¼ float32 [-1,1]ë¡œ ì½ê¸° (Kspon í‘œì¤€: 16kHz)."""
    data = np.fromfile(path, dtype=np.int16)     # s16le
    wav = data.astype(np.float32) / 32768.0      # [-1, 1]
    return wav


def parse_audio(audio_path: str, del_silence: bool = False,
                audio_extension: Optional[str] = None) -> Tensor:
    """
    - .pcmì´ë©´ RAW s16le(16k/mono)ë¡œ ì§ì ‘ ë¡œë“œ
    - ê·¸ ì™¸ í¬ë§·(wav ë“±)ì€ ê¸°ì¡´ load_audio ì‚¬ìš©
    - ì¶œë ¥: (T, 80) fbank with CMVN
    """
    ext = (Path(audio_path).suffix.lower().lstrip(".") or "wav") if audio_extension is None else audio_extension.lower()

    if ext == "pcm":
        signal = _load_pcm16le(audio_path)                    # 16k ê°€ì •
    else:
        signal = load_audio(audio_path, del_silence, extension=ext)

    if signal is None:
        raise RuntimeError(f"Failed to load audio: {audio_path} (ext={ext})")

    feat = torchaudio.compliance.kaldi.fbank(
        waveform=Tensor(signal).unsqueeze(0),
        num_mel_bins=80,
        frame_length=20,
        frame_shift=10,
        window_type="hamming",
        sample_frequency=16000,                               # ëª…ì‹œì ìœ¼ë¡œ 16kHz
    ).transpose(0, 1).numpy()

    # CMVN
    feat = (feat - feat.mean()) / (np.std(feat) + 1e-12)
    return torch.FloatTensor(feat).transpose(0, 1)            # (T, 80)


# -----------------------------
# ë‹¨ì¼ ëª¨ë¸ ì—”ì§„
# -----------------------------
class ASRInference:
    def __init__(
        self,
        model_path: str,
        vocab_path: str,
        device: str = "cpu",
        dtype: str = "float32",
        warmup: bool = False,
        adapter_path: Optional[str] = None,   # â† NEW
    ):
        """
        ëª¨ë¸/ì‚¬ì „ì„ ë©”ëª¨ë¦¬ì— ê³ ì • ë¡œë”©.
        adapter_path ê°€ ì£¼ì–´ì§€ë©´ DeepSpeech2 ëª¨ë¸ì— MLPAdapter ë¥¼ ë¶™ì—¬ì„œ ì‚¬ìš©.
        """
        self.device = device
        self.adapter_path = adapter_path
        self.adapter_loaded: bool = False

        # PyTorch 2.6+ ëŒ€ì‘: ì•ˆì „ëª©ë¡ + weights_only=False ë¡œë“œ, DataParallel í•´ì œ
        add_safe_globals([DataParallel])
        obj = torch.load(model_path, map_location="cpu", weights_only=False)
        self.model = obj.module if hasattr(obj, "module") else obj
        self.model = self.model.to(self.device).eval()

        # dtype ì „í™˜(optional)
        if dtype == "float16":
            self.model = self.model.half()
        elif dtype == "bfloat16":
            self.model = self.model.bfloat16()
        # else float32 default

        # Adapter ë¶™ì´ê¸° (í•„ìš”í•œ ê²½ìš°, DeepSpeech2 ì „ìš©)
        if adapter_path:
            self._attach_adapter(adapter_path)

        # KoSpeech vocab
        self.vocab = KsponSpeechVocabulary(vocab_path)

        # ì„±ëŠ¥ ê´€ë ¨ ì„¤ì •
        torch.set_grad_enabled(False)
        torch.backends.cudnn.benchmark = True

        # optional warmup
        if warmup:
            self._warmup()

    def _attach_adapter(self, adapter_path: str) -> None:
        """DeepSpeech2 ìš© adapter .pt ë¥¼ ë¡œë“œí•´ì„œ ëª¨ë¸ì— ë¶™ì¸ë‹¤."""
        if not isinstance(self.model, DeepSpeech2):
            print(f"[WARN] adapter_path={adapter_path} ì´ ì§€ì •ë˜ì—ˆì§€ë§Œ ëª¨ë¸ì´ DeepSpeech2 ê°€ ì•„ë‹ˆë¼ì„œ ë¬´ì‹œí•©ë‹ˆë‹¤.")
            return

        try:
            # ğŸ”¥ PyTorch 2.6+ ê¸°ë³¸ weights_only=True ë•Œë¬¸ì— ì‹¤íŒ¨í–ˆìœ¼ë‹ˆ,
            #    ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ weights_only=False ë¡œ "ì˜›ë‚  ë°©ì‹" ë¡œë” ì‚¬ìš©
            ckpt = torch.load(adapter_path, map_location="cpu", weights_only=False)
        except Exception as e:
            print(f"[WARN] adapter ë¡œë“œ ì‹¤íŒ¨ ({adapter_path}): {e}")
            return

        # ìš°ë¦¬ê°€ AdapterManager.save_adapter(...) ì—ì„œ ì €ì¥í•œ í˜•ì‹:
        # {
        #   'adapter_state_dict': ...,
        #   'input_dim': int,
        #   'hidden_dims': list or ListConfig,
        #   'output_dim': int,
        #   'adapter_name': str,
        # }
        state_dict = ckpt.get("adapter_state_dict")
        input_dim = ckpt.get("input_dim")
        hidden_dims_raw = ckpt.get("hidden_dims")
        output_dim = ckpt.get("output_dim")

        if state_dict is None or input_dim is None or hidden_dims_raw is None or output_dim is None:
            print(f"[WARN] adapter ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {adapter_path}")
            return

        # ğŸ”¥ ListConfig ê°™ì€ ê²ƒë„ ì¼ë°˜ list ë¡œ ë³€í™˜
        try:
            hidden_dims = list(hidden_dims_raw)
        except TypeError:
            hidden_dims = [int(hidden_dims_raw)]

        adapter = MLPAdapter(
            input_dim=input_dim,
            hidden_dims=hidden_dims,
            output_dim=output_dim,
            dropout_p=0.0,  # ì¶”ë¡ ì—ì„œëŠ” dropout ì•ˆ ì”€
        )
        adapter.load_state_dict(state_dict)
        adapter = adapter.to(self.device)

        # ëª¨ë¸ì— ë¶€ì°©
        self.model.adapter = adapter
        setattr(self.model, "use_adapter", True)

        self.adapter_loaded = True
        print(f"[INFO] Adapter loaded and attached from: {adapter_path}")


    def _warmup(self):
        dummy = torch.zeros(100, 80, dtype=torch.float32)
        lengths = torch.LongTensor([dummy.size(0)])
        dummy = dummy.to(self.device)
        if self._is_amp():
            dummy = self._to_amp(dummy)

        with torch.inference_mode():
            _ = self._recognize_tensor(dummy, lengths)

    def _is_amp(self) -> bool:
        return any(
            p.is_floating_point() and p.dtype in (torch.float16, torch.bfloat16)
            for p in self.model.parameters()
        )

    def _to_amp(self, x: torch.Tensor) -> torch.Tensor:
        # ëª¨ë¸ dtypeì— ë§ì¶° feature dtypeë„ ë§ì¶¤
        dt = next(self.model.parameters()).dtype
        if dt == torch.float16:
            return x.half()
        if dt == torch.bfloat16:
            return x.bfloat16()
        return x

    def _recognize_tensor(self, feature: torch.Tensor, input_length: torch.LongTensor):
        m = self.model

        if isinstance(m, ListenAttendSpell):
            m.encoder.device = self.device
            m.decoder.device = self.device
            y_hats = m.recognize(feature.unsqueeze(0), input_length)

        elif isinstance(m, DeepSpeech2):
            # DeepSpeech2 + (optional) adapter
            m.device = self.device
            use_adapter = getattr(m, "use_adapter", False) and getattr(m, "adapter", None) is not None

            if use_adapter:
                # forward ë¥¼ ì§ì ‘ í˜¸ì¶œí•´ adapter ì¶œë ¥ì„ ë°›ì•„ decode
                outputs = m(feature.unsqueeze(0), input_length)
                if isinstance(outputs, (tuple, list)):
                    if len(outputs) == 3:
                        _, _, adapter_log_probs = outputs
                        predicted_log_probs = adapter_log_probs
                    elif len(outputs) == 2:
                        predicted_log_probs, _ = outputs
                    else:
                        predicted_log_probs = outputs[0]
                else:
                    predicted_log_probs = outputs

                if getattr(m, "decoder", None) is not None:
                    y_hats = m.decoder.decode(predicted_log_probs)
                else:
                    y_hats = m.decode(predicted_log_probs)
            else:
                # ê¸°ì¡´ ê²½ë¡œ ê·¸ëŒ€ë¡œ
                y_hats = m.recognize(feature.unsqueeze(0), input_length)

        elif isinstance(m, (SpeechTransformer, Jasper, Conformer)):
            y_hats = m.recognize(feature.unsqueeze(0), input_length)

        else:
            y_hats = m.recognize(feature.unsqueeze(0), input_length)

        return y_hats

    def infer_one(
        self,
        audio_path: str,
        save_json: bool = False,
        out_dir: Optional[str] = None,
        audio_extension: Optional[str] = None,
    ):
        """
        ë‹¨ì¼ íŒŒì¼ ì¶”ë¡  + ì‹œê°„ ì¸¡ì •.
        return: dict(payload + timings)
        """
        t_total0 = time.perf_counter()

        # 1) íŠ¹ì§• ì¶”ì¶œ
        t_feat0 = time.perf_counter()
        feature = parse_audio(audio_path, del_silence=False, audio_extension=audio_extension)
        t_feat1 = time.perf_counter()

        # 2) ê¸¸ì´/ë””ë°”ì´ìŠ¤ ì´ë™
        input_length = torch.LongTensor([feature.size(0)])
        feature = feature.to(self.device)
        if self._is_amp():
            feature = self._to_amp(feature)

        # 3) ì¶”ë¡ 
        t_inf0 = time.perf_counter()
        with torch.inference_mode():
            y_hats = self._recognize_tensor(feature, input_length)
            if str(self.device).startswith("cuda"):
                torch.cuda.synchronize()
        t_inf1 = time.perf_counter()

        # 4) í›„ì²˜ë¦¬
        sentence = self.vocab.label_to_string(y_hats.cpu().detach().numpy())
        sentence = revise(sentence)
        text = sentence[0] if isinstance(sentence, (list, tuple)) else sentence
        text = text.strip()

        payload = {
            "title": Path(audio_path).name,
            "text": text,
        }

        # 5) JSON ì €ì¥ (ì˜µì…˜)
        if save_json:
            if out_dir:
                out_dir = Path(out_dir)
                out_dir.mkdir(parents=True, exist_ok=True)
                out_path = out_dir / (Path(audio_path).stem + ".json")
            else:
                out_path = Path(audio_path).with_suffix(".json")
            with out_path.open("w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False, indent=2)

        t_total1 = time.perf_counter()

        timings_ms = {
            "feature_ms": int((t_feat1 - t_feat0) * 1000),
            "inference_ms": int((t_inf1 - t_inf0) * 1000),
            "total_ms": int((t_total1 - t_total0) * 1000),
        }
        return payload, timings_ms


# -----------------------------
# ë‹¤ì¤‘ ëª¨ë¸ ì—”ì§„
# -----------------------------
class MultiASRInference:
    """
    ìµœëŒ€ 3ê°œ ëª¨ë¸ê¹Œì§€ ë™ì‹œì— ì˜¬ë ¤ë‘ê³ ,
    ì´ë¦„ìœ¼ë¡œ ì„ íƒí•´ì„œ ì¶”ë¡ í•˜ëŠ” ë˜í¼.
    ê° ëª¨ë¸ë§ˆë‹¤ adapter ë¥¼ ë³„ë„ë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ.
    """
    def __init__(
        self,
        model_paths: Sequence[str],
        model_names: Sequence[str],
        vocab_path: str,
        device: str = "cpu",
        dtype: str = "float32",
        warmup: bool = False,
        adapter_paths: Optional[Sequence[Optional[str]]] = None,  # â† NEW
    ):
        if len(model_paths) == 0:
            raise ValueError("model_paths ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        if len(model_paths) > 3:
            raise ValueError("ìµœëŒ€ 3ê°œ ëª¨ë¸ê¹Œì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
        if len(model_names) != len(model_paths):
            raise ValueError("model_names ê¸¸ì´ëŠ” model_paths ê¸¸ì´ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")

        self.engines: Dict[str, ASRInference] = {}
        for idx, (name, path) in enumerate(zip(model_names, model_paths)):
            if name in self.engines:
                raise ValueError(f"ì¤‘ë³µëœ ëª¨ë¸ ì´ë¦„: {name}")

            adapter_path: Optional[str] = None
            if adapter_paths is not None and idx < len(adapter_paths):
                ap = adapter_paths[idx]
                if ap and str(ap).lower() not in ("none", "-"):
                    adapter_path = ap

            print(f"[INFO] load model '{name}' from {path}")
            if adapter_path:
                print(f"       -> adapter: {adapter_path}")

            self.engines[name] = ASRInference(
                model_path=path,
                vocab_path=vocab_path,
                device=device,
                dtype=dtype,
                warmup=warmup,
                adapter_path=adapter_path,
            )
        self.default_name = model_names[0]

    @property
    def model_names(self) -> List[str]:
        return list(self.engines.keys())

    def infer_one(
        self,
        model_name: Optional[str],
        audio_path: str,
        save_json: bool = False,
        out_dir: Optional[str] = None,
        audio_extension: Optional[str] = None,
    ):
        name = model_name or self.default_name
        if name not in self.engines:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ ì´ë¦„: {name} (ì‚¬ìš© ê°€ëŠ¥: {self.model_names})")
        engine = self.engines[name]
        payload, t = engine.infer_one(
            audio_path=audio_path,
            save_json=save_json,
            out_dir=out_dir,
            audio_extension=audio_extension,
        )
        payload["model_name"] = name
        return payload, t



# -----------------------------
# CLI / REPL ìœ í‹¸
# -----------------------------
def _parse_model_and_path(
    s: str,
    valid_models: Sequence[str],
    default_model: str,
) -> Tuple[str, str]:
    """
    í•œ ì¤„ì—ì„œ ëª¨ë¸ ì´ë¦„ê³¼ ê²½ë¡œë¥¼ íŒŒì‹±.
    ì§€ì› í˜•ì‹:
      - "path/to.wav"             -> (default_model, path)
      - "model_name path/to.wav"  -> (model_name, path)
      - "model_name:path/to.wav"  -> (model_name, path)
    """
    s = s.strip()
    if not s:
        return default_model, ""

    # "name:path" í˜•ì‹ ë¨¼ì € ì²´í¬
    if ":" in s:
        maybe_name, rest = s.split(":", 1)
        maybe_name = maybe_name.strip()
        rest = rest.strip()
        if maybe_name in valid_models and rest:
            return maybe_name, rest

    # ê³µë°± ê¸°ì¤€: "name path"
    tokens = s.split()
    if len(tokens) >= 2 and tokens[0] in valid_models:
        name = tokens[0]
        path = " ".join(tokens[1:])
        return name, path

    # ê·¸ ì™¸: ì „ë¶€ path ë¡œ ë³´ê³  default ëª¨ë¸ ì‚¬ìš©
    return default_model, s


def process_paths_single(engine: ASRInference, paths: Sequence[str],
                         save_json: bool, out_dir: Optional[str]):
    for p in paths:
        p = p.strip()
        if not p:
            continue
        if not Path(p).exists():
            print(f"[ERROR] File not found: {p}", file=sys.stderr)
            continue

        payload, t = engine.infer_one(p, save_json=save_json, out_dir=out_dir)
        print(f"\n=== {payload['title']} ===")
        print(payload["text"])
        print(f"[timing] feature: {t['feature_ms']} ms | inference: {t['inference_ms']} ms | total: {t['total_ms']} ms")


def process_paths_multi(multi: MultiASRInference, paths: Sequence[str],
                        save_json: bool, out_dir: Optional[str]):
    for s in paths:
        s = s.strip()
        if not s:
            continue
        model_name, path = _parse_model_and_path(s, multi.model_names, multi.default_name)
        if not path:
            continue
        if not Path(path).exists():
            print(f"[ERROR][{model_name}] File not found: {path}", file=sys.stderr)
            continue

        payload, t = multi.infer_one(model_name, path, save_json=save_json, out_dir=out_dir)
        print(f"\n=== [{payload['model_name']}] {payload['title']} ===")
        print(payload["text"])
        print(f"[timing] feature: {t['feature_ms']} ms | inference: {t['inference_ms']} ms | total: {t['total_ms']} ms")


def repl_single(engine: ASRInference, save_json: bool, out_dir: Optional[str]):
    print("-> íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ ë¹ˆ ì¤„ ë˜ëŠ” q.")
    while True:
        try:
            line = input("> ").strip()
        except EOFError:
            break
        if line.lower() in {"q", "quit", "exit"} or line == "":
            break
        process_paths_single(engine, [line], save_json, out_dir)


def repl_multi(multi: MultiASRInference, save_json: bool, out_dir: Optional[str]):
    names = ", ".join(multi.model_names)
    print("-> ëª¨ë¸ ì´ë¦„ê³¼ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ ë¹ˆ ì¤„ ë˜ëŠ” q.")
    print(f"   ì˜ˆ) normal /path/to.wav  ë˜ëŠ”  neuro:/path/to.wav")
    print(f"   ëª¨ë¸ ì´ë¦„ì„ ìƒëµí•˜ë©´ ê¸°ë³¸ ëª¨ë¸({multi.default_name})ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    print(f"   ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸: {names}")
    while True:
        try:
            line = input("> ").strip()
        except EOFError:
            break
        if line.lower() in {"q", "quit", "exit"} or line == "":
            break
        model_name, path = _parse_model_and_path(line, multi.model_names, multi.default_name)
        process_paths_multi(multi, [f"{model_name} {path}"], save_json, out_dir)


# -----------------------------
# main
# -----------------------------
def main():
    parser = argparse.ArgumentParser(
        description="KoSpeech ASR - One-time load, multi-file / multi-model inference"
    )
    # ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œ (ê¸°ì¡´)
    parser.add_argument("--model_path", type=str, help="ë‹¨ì¼ ëª¨ë¸ ê²½ë¡œ")

    # ë©€í‹° ëª¨ë¸ ëª¨ë“œ (ìµœëŒ€ 3ê°œ)
    parser.add_argument(
        "--multi_model_paths",
        type=str,
        nargs="+",
        help="ì—¬ëŸ¬ ëª¨ë¸ ê²½ë¡œ (ìµœëŒ€ 3ê°œ). ì˜ˆ: --multi_model_paths normal.pt hearing.pt neuro.pt",
    )
    parser.add_argument(
        "--model_names",
        type=str,
        nargs="*",
        help="ê° ëª¨ë¸ì˜ ì´ë¦„. ì˜ˆ: --model_names normal hearing neuro (ë¯¸ì§€ì •ì‹œ m1,m2,... ì‚¬ìš©)",
    )
    parser.add_argument(
        "--default_model",
        type=str,
        default=None,
        help="ëª¨ë¸ ì´ë¦„ì„ ìƒëµí–ˆì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: ì²« ë²ˆì§¸ ëª¨ë¸)",
    )

    parser.add_argument(
        "--adapter_paths",
        type=str,
        nargs="*",
        help=(
            "ë©€í‹° ëª¨ë¸ ëª¨ë“œì—ì„œ ê° ëª¨ë¸ì— ëŒ€ì‘ë˜ëŠ” adapter .pt ê²½ë¡œ ëª©ë¡. "
            "ê¸¸ì´ê°€ --multi_model_paths ì™€ ê°™ê±°ë‚˜ ë” ì§§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
            "ë¹„ì–´ìˆê±°ë‚˜ 'none' / '-' ì¸ í•­ëª©ì€ í•´ë‹¹ ëª¨ë¸ì—ì„œ adapter ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        ),
    )


    parser.add_argument(
        "--adapter_path",
        type=str,
        default=None,
        help="ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  adapter .pt ê²½ë¡œ (ì„ íƒ, DeepSpeech2 ì „ìš©)",
    )



    parser.add_argument("--vocab_path", type=str, default="data/vocab/aihub_character_vocabs.csv")
    parser.add_argument("--device", type=str, default="cpu")  # cpu / cuda / cuda:0
    parser.add_argument("--dtype", type=str, default="float32",
                        choices=["float32", "float16", "bfloat16"])
    parser.add_argument("--warmup", action="store_true",
                        help="ëª¨ë¸ ë¡œë“œ ì§í›„ ì§§ì€ ì›Œë°ì—… ì‹¤í–‰")

    # ì…ì¶œë ¥ ëª¨ë“œ
    parser.add_argument("--paths", type=str, nargs="*", help="ë¯¸ë¦¬ ì§€ì •ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë¦¬ìŠ¤íŠ¸")
    parser.add_argument("--stdin", action="store_true", help="í‘œì¤€ì…ë ¥ìœ¼ë¡œ íŒŒì¼ê²½ë¡œ ë¼ì¸ë³„ ì²˜ë¦¬")
    parser.add_argument("--save_json", action="store_true", help="ê° íŒŒì¼ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥")
    parser.add_argument("--out_dir", type=str, default=None,
                        help="JSON ì €ì¥ ë””ë ‰í† ë¦¬ (ë¯¸ì§€ì •ì‹œ ì…ë ¥íŒŒì¼ ì˜†ì— .json)")

    args = parser.parse_args()

    # ëª¨ë“œ ê²°ì •: ë©€í‹° ëª¨ë¸ ìš°ì„ 
    if args.multi_model_paths:
        if args.model_path:
            print("[WARN] --multi_model_paths ì™€ --model_path ê°€ ë™ì‹œì— ì§€ì •ë˜ì—ˆìŠµë‹ˆë‹¤. "
                  "--multi_model_paths ë¥¼ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.", file=sys.stderr)

        if len(args.multi_model_paths) > 3:
            parser.error("ìµœëŒ€ 3ê°œ ëª¨ë¸ê¹Œì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤ (--multi_model_paths).")

        if args.model_names:
            if len(args.model_names) != len(args.multi_model_paths):
                parser.error("--model_names ê¸¸ì´ëŠ” --multi_model_paths ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
            model_names = args.model_names
        else:
            # ê¸°ë³¸ ì´ë¦„: m1, m2, ...
            model_names = [f"m{i+1}" for i in range(len(args.multi_model_paths))]

        # adapter_paths ì •ê·œí™” (ì„ íƒ)
        adapter_paths: Optional[List[Optional[str]]] = None
        if args.adapter_paths:
            if len(args.adapter_paths) > len(args.multi_model_paths):
                parser.error("--adapter_paths ê¸¸ì´ëŠ” --multi_model_paths ë³´ë‹¤ ê¸¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            adapter_paths = list(args.adapter_paths)
            # ì§§ìœ¼ë©´ ë’¤ë¥¼ None ìœ¼ë¡œ ì±„ì›€
            if len(adapter_paths) < len(args.multi_model_paths):
                adapter_paths += [None] * (len(args.multi_model_paths) - len(adapter_paths))



        multi = MultiASRInference(
            model_paths=args.multi_model_paths,
            model_names=model_names,
            vocab_path=args.vocab_path,
            device=args.device,
            dtype=args.dtype,
            warmup=args.warmup,
            adapter_paths=adapter_paths,   # â† NEW
        )

        # default_model ì§€ì •
        if args.default_model:
            if args.default_model not in multi.model_names:
                parser.error(f"--default_model {args.default_model} ì€/ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤. "
                             f"ì‚¬ìš© ê°€ëŠ¥: {multi.model_names}")
            multi.default_name = args.default_model

        if args.paths:
            process_paths_multi(multi, args.paths, args.save_json, args.out_dir)
        elif args.stdin:
            lines = [line.rstrip("\n") for line in sys.stdin]
            process_paths_multi(multi, lines, args.save_json, args.out_dir)
        else:
            repl_multi(multi, args.save_json, args.out_dir)

    else:
        # ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œ (ì´ì „ê³¼ ë™ì¼)
        if not args.model_path:
            parser.error("ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œì—ì„œëŠ” --model_path ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤ "
                         "(ë˜ëŠ” ë©€í‹° ëª¨ë¸ ëª¨ë“œë¡œ --multi_model_paths ì‚¬ìš©).")

        engine = ASRInference(
            model_path=args.model_path,
            vocab_path=args.vocab_path,
            device=args.device,
            dtype=args.dtype,
            warmup=args.warmup,
            adapter_path=args.adapter_path,
        )

        if args.paths:
            process_paths_single(engine, args.paths, args.save_json, args.out_dir)
        elif args.stdin:
            lines = [line.rstrip("\n") for line in sys.stdin]
            process_paths_single(engine, lines, args.save_json, args.out_dir)
        else:
            repl_single(engine, args.save_json, args.out_dir)


if __name__ == "__main__":
    main()
