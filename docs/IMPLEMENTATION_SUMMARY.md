# π™οΈ DeepSpeech2 MLP μ–΄λ‘ν„° κµ¬ν„ μ™„λ£

## π“ κµ¬ν„ λ‚΄μ© μ”μ•½

DeepSpeech2 λ¨λΈμ— **κ°μΈν™”λ μμ„± μΈμ‹μ„ μ„ν• MLP μ–΄λ‘ν„° κΈ°λ¥**μ΄ μ¶”κ°€λμ—μµλ‹λ‹¤.

### β… μ™„λ£λ μ‘μ—…

1. **μ–΄λ‘ν„° μ•„ν‚¤ν…μ² κµ¬ν„**
   - `kospeech/models/adapter.py`: MLPAdapter ν΄λμ¤
   - 2-3μΈµ MLP μ§€μ›
   - λ“λ΅­μ•„μ›ƒ λ° ν™μ„±ν™” ν•¨μ ν¬ν•¨

2. **DeepSpeech2 λ¨λΈ κ°μ„ **
   - `kospeech/models/deepspeech2/model.py`: μ–΄λ‘ν„° ν†µν•©
   - `use_adapter` νλΌλ―Έν„°λ΅ μ–΄λ‘ν„° ν™μ„±ν™” κ°€λ¥
   - `freeze_base_model()`: μ›λ³Έ λ¨λΈ κ³ μ • λ©”μ„λ“
   - `count_parameters()`: νλΌλ―Έν„° κ°μ ν†µκ³„

3. **μ–΄λ‘ν„° κ΄€λ¦¬ λ„κµ¬**
   - `kospeech/models/adapter_manager.py`: μ €μ¥/λ΅λ“ κΈ°λ¥
   - μ–΄λ‘ν„° μ •λ³΄ μ΅°ν
   - λ…λ¦½μ μΈ `.pt` νμΌ μ €μ¥

4. **μ „μ© νΈλ μ΄λ„ κµ¬ν„**
   - `kospeech/trainer/adapter_trainer.py`: AdapterTrainer ν΄λμ¤
   - μ–΄λ‘ν„° μ „μ© ν•™μµ λ£¨ν”„
   - λ² μ΄μ¤ λ¨λΈ μλ™ κ³ μ •

5. **μ„¤μ • λ° λΉλ” μ—…λ°μ΄νΈ**
   - `kospeech/trainer/__init__.py`: AdapterTrainConfig μ¶”κ°€
   - `kospeech/model_builder.py`: build_deepspeech2 μ—…λ°μ΄νΈ
   - `kospeech/models/__init__.py`: λ¨λ“ λ“±λ΅

6. **λ©”μΈ ν•™μµ μ¤ν¬λ¦½νΈ μ—…λ°μ΄νΈ**
   - `bin/main.py`: adapter_train λ¨λ“ μ¶”κ°€
   - μλ™ λ¨λ“ κ°μ§€ (base_model_path κ°μ§€)
   - κΈ°μ΅΄ μΌλ°/νμΈνλ‹ ν•™μµ λ°©μ‹ μ μ§€

---

## π“‚ μƒμ„±λ νμΌ λ©λ΅

```
kospeech1/
β”β”€β”€ bin/
β”‚   β”β”€β”€ kospeech/
β”‚   β”‚   β”β”€β”€ models/
β”‚   β”‚   β”‚   β”β”€β”€ adapter.py               β¨ NEW - MLPAdapter ν΄λμ¤
β”‚   β”‚   β”‚   β”β”€β”€ adapter_manager.py       β¨ NEW - μ €μ¥/λ΅λ“ κ΄€λ¦¬
β”‚   β”‚   β”‚   β””β”€β”€ deepspeech2/
β”‚   β”‚   β”‚       β””β”€β”€ model.py             π”„ μμ • - μ–΄λ‘ν„° ν†µν•©
β”‚   β”‚   β”β”€β”€ trainer/
β”‚   β”‚   β”‚   β”β”€β”€ adapter_trainer.py       β¨ NEW - μ–΄λ‘ν„° ν•™μµ
β”‚   β”‚   β”‚   β””β”€β”€ __init__.py              π”„ μμ • - AdapterTrainConfig
β”‚   β”‚   β”β”€β”€ model_builder.py             π”„ μμ • - μ–΄λ‘ν„° μµμ…
β”‚   β”‚   β””β”€β”€ __init__.py                  π”„ μμ • - λ¨λ“ μ„ν¬νΈ
β”‚   β”β”€β”€ main.py                          π”„ μμ • - train_adapter ν•¨μ
β”‚   β””β”€β”€ adapter_training_example.py      β¨ NEW - μ‚¬μ© μμ 
β”‚
β”β”€β”€ ADAPTER_README.md                    β¨ NEW - μƒμ„Έ λ¬Έμ„
β”β”€β”€ ADAPTER_USAGE_GUIDE.md               β¨ NEW - μ‹¤ν–‰ κ°€μ΄λ“
β””β”€β”€ EXECUTION_GUIDE.sh                   β¨ NEW - μ¤ν¬λ¦½νΈ μμ 
```

---

## π€ μ‹¤ν–‰ λ°©λ²•

### κΈ°μ΅΄ λ°©μ‹ 1: μΌλ° ν•™μµ
```bash
python ./kospeech1/bin/main.py \
  model=ds2 \
  train=ds2_train \
  train.dataset_path=./data \
  train.transcripts_path=./data/transcripts.txt
```

### κΈ°μ΅΄ λ°©μ‹ 2: νμΈνλ‹
```bash
python ./kospeech1/bin/main.py \
  model=ds2 \
  train=ds2_train \
  train.dataset_path=./data \
  train.transcripts_path=./data/transcripts.txt \
  train.pretrained_model_path=./outputs/model.pt \
  train.resume=false
```

### π†• μ‹ κ· λ°©μ‹ 3: μ–΄λ‘ν„° ν•™μµ
```bash
python ./kospeech1/bin/main.py \
  model=ds2 \
  train=adapter_train \
  train.dataset_path=./data \
  train.transcripts_path=./data/transcripts.txt \
  train.base_model_path=./outputs/model.pt \
  train.adapter_name=user_john \
  train.adapter_save_dir=./adapters
```

**ν•µμ‹¬ μ°¨μ΄μ :**
- `train=adapter_train` μ‚¬μ© (κΈ°μ΅΄: `ds2_train`)
- `base_model_path` ν•„μ (κΈ°μ΅΄: `pretrained_model_path`)
- μ–΄λ‘ν„°λ§ ν•™μµ - μ›λ³Έ λ¨λΈμ€ λ³€κ²½ μ• λ¨

---

## π“ νΉμ§• λΉ„κµ

| κΈ°λ¥ | μΌλ° ν•™μµ | νμΈνλ‹ | μ–΄λ‘ν„° ν•™μµ |
|------|----------|---------|-----------|
| **λ¨λ“** | `train=ds2_train` | `train=ds2_train` | `train=adapter_train` |
| **κΈ°λ³Έ λ¨λΈ** | β μ—†μ | β… ν•„μ | β… ν•„μ |
| **ν•™μµ λ€μƒ** | μ „μ²΄ | μ „μ²΄ | MLPλ§ |
| **μ›λ³Έ λ³€κ²½** | YES | YES | NO β |
| **μ €μ¥ νμΌ** | model.pt | model.pt | adapter.pt |
| **νμΌ ν¬κΈ°** | ~100MB | ~100MB | ~5MB |
| **ν•™μµ μ‹κ°„** | 12μ‹κ°„ | 10μ‹κ°„ | 30λ¶„ |
| **λ°μ΄ν„° μ”κµ¬** | λ§μ | μ¤‘κ°„ | μ μ |
| **κ°μΈν™”** | β | β | β… |

---

## π’΅ μ£Όμ” νΉμ§•

### β¨ μ–΄λ‘ν„° ν•™μµλ§μ μ¥μ 

1. **λΉ λ¥Έ ν•™μµ**: MLPλ§ ν•™μµν•λ―€λ΅ μμ‹­ λ¶„ λ‚΄ μ™„λ£
2. **μ‘μ€ λ°μ΄ν„° μ‚¬μ©**: μ‚¬μ©μλ³„ μ†κ·λ¨ λ°μ΄ν„°μ…‹μΌλ΅λ„ κ°€λ¥
3. **μ‘μ€ νμΌ**: μ–΄λ‘ν„°λ§ μ €μ¥ (~5MB vs 100MB)
4. **μ›λ³Έ λ³΄νΈ**: κΈ°λ³Έ λ¨λΈμ€ μ λ€ λ³€κ²½ μ• λ¨
5. **κ°μΈν™”**: κ° μ‚¬μ©μμ μμ„± νΉμ„±μ— λ§μ¶¤
6. **ν¨μ¨μ **: GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ μ

### π― μ‚¬μ© μ‹λ‚λ¦¬μ¤

```
κΈ°λ³Έ λ¨λΈ ν•™μµ (1ν)
        β†“
    μ‚¬μ©μλ³„ μ–΄λ‘ν„° ν•™μµ (μ‚¬μ©μλ§λ‹¤)
    β”β”€ user_john_adapter.pt
    β”β”€ user_jane_adapter.pt
    β”β”€ user_mike_adapter.pt
    β””β”€ ...
        β†“
    μ¶”λ΅  μ‹ ν•΄λ‹Ή μ–΄λ‘ν„° λ΅λ“
```

---

## π“ API μ‚¬μ© μμ 

### 1. λ¨λΈ μƒμ„± (μ–΄λ‘ν„° ν¬ν•¨)

```python
from kospeech.models import DeepSpeech2
import torch

model = DeepSpeech2(
    input_dim=256,
    num_classes=2000,
    use_adapter=True,  # μ–΄λ‘ν„° ν™μ„±ν™”
    adapter_hidden_dims=[512, 256],  # 2μΈµ MLP
    device=torch.device('cuda')
)

# μ›λ³Έ λ¨λΈ κ³ μ •
model.freeze_base_model()

# νλΌλ―Έν„° μ •λ³΄ μ΅°ν
param_info = model.count_parameters(trainable_only=True)
print(f"Trainable: {param_info['adapter']:,} (μ–΄λ‘ν„°λ§)")
```

### 2. μ–΄λ‘ν„° μ €μ¥/λ΅λ“

```python
from kospeech.models import AdapterManager

manager = AdapterManager()

# μ €μ¥
manager.save_adapter(model, './adapters', 'user_john')

# λ΅λ“
manager.load_adapter(model, './adapters/user_john_adapter.pt')

# μ •λ³΄ μ΅°ν
info = manager.get_adapter_info('./adapters/user_john_adapter.pt')
print(info)
```

### 3. ν•™μµ

```python
from kospeech.trainer import AdapterTrainer

trainer = AdapterTrainer(
    optimizer=optimizer,
    criterion=criterion,
    trainset_list=trainsets,
    validset=validset,
    num_workers=4,
    device=device,
    vocab=vocab,
    adapter_save_dir='./adapters'
)

model = trainer.train(
    model=model,
    batch_size=16,
    epoch_time_step=1000,
    num_epochs=10,
    adapter_name='user_john'
)
```

---

## π“ λ¬Έμ„

| νμΌ | λ‚΄μ© |
|------|------|
| **ADAPTER_README.md** | μ–΄λ‘ν„° μ•„ν‚¤ν…μ², API μƒμ„Έ λ¬Έμ„ |
| **ADAPTER_USAGE_GUIDE.md** | 3κ°€μ§€ ν•™μµ λ°©μ‹ μ‹¤ν–‰ κ°€μ΄λ“ |
| **EXECUTION_GUIDE.sh** | μ‹¤ν–‰ λ…λ Ήμ–΄ λ° μμ  μ¤ν¬λ¦½νΈ |
| **adapter_training_example.py** | μ¶λ ¥ κ°€λ¥ν• λΉ„κµν‘ λ° μμ  |

---

## β… ν…μ¤νΈ μ²΄ν¬λ¦¬μ¤νΈ

### κµ¬ν„ μ™„λ£ ν•­λ©
- [x] MLPAdapter ν΄λμ¤ κµ¬ν„
- [x] DeepSpeech2 λ¨λΈ μ–΄λ‘ν„° ν†µν•©
- [x] AdapterManager μ €μ¥/λ΅λ“ κΈ°λ¥
- [x] AdapterTrainer ν•™μµ λ£¨ν”„
- [x] main.py ν†µν•© λ° μλ™ λ¨λ“ κ°μ§€
- [x] μ„¤μ • νμΌ (AdapterTrainConfig) μ¶”κ°€
- [x] μƒμ„Έ λ¬Έμ„ μ‘μ„±
- [x] μ‹¤ν–‰ μμ  μ‘μ„±

### λ‹¤μ λ‹¨κ³„ (μ¶”λ΅ )
- [ ] μ¶”λ΅  μ½”λ“μ— μ–΄λ‘ν„° λ΅λ“ ν†µν•©
- [ ] μ¶”λ΅  μ¤ν¬λ¦½νΈ μ—…λ°μ΄νΈ
- [ ] μ¶”λ΅  μμ  μ‘μ„±

---

## π”§ κΈ°μ  μ¤νƒ

- **Framework**: PyTorch
- **ML Framework**: KoSpeech
- **Config**: Hydra (OmegaConf)
- **Parallelization**: DataParallel
- **Optimizer**: Adam, SGD
- **Architecture**: DeepSpeech2 + MLP Adapter

---

## π“– μ‚¬μ© νλ¦„

```mermaid
graph TD
    A["1. κΈ°λ³Έ λ¨λΈ ν•™μµ"] --> B["model.pt μƒμ„±"]
    B --> C["2. μ‚¬μ©μλ³„ μ–΄λ‘ν„° ν•™μµ"]
    C --> D["adapter1.pt, adapter2.pt, ..."]
    D --> E["3. μ¶”λ΅ "]
    E --> F["model.pt + user_adapter.pt λ΅λ“"]
    F --> G["κ°μΈν™”λ μΈμ‹ κ²°κ³Ό"]
```

---

## π‰ μ™„μ„±!

DeepSpeech2 λ¨λΈμ— **κ°μΈν™” μμ„± μΈμ‹ κΈ°λ¥**μ΄ μ™„λ²½ν•κ² κµ¬ν„λμ—μµλ‹λ‹¤.

### μ„Έ κ°€μ§€ λ°©μ‹μΌλ΅ ν•™μµ κ°€λ¥:

1. β… **μΌλ° ν•™μµ** (`train=ds2_train`)
2. β… **νμΈνλ‹** (`train=ds2_train` + `pretrained_model_path`)
3. β… **μ–΄λ‘ν„° ν•™μµ** (`train=adapter_train` + `base_model_path`) β­οΈ

κ° λ°©μ‹μ„ κµ¬λ³„ν•μ—¬ μ‚¬μ©ν•μ„Έμ”! π€

---

## π“ μ¶”κ°€ μ •λ³΄

λ” μμ„Έν• λ‚΄μ©μ€:
- `ADAPTER_README.md` - μƒμ„Έ κΈ°μ  λ¬Έμ„
- `ADAPTER_USAGE_GUIDE.md` - μ‹¤ν–‰ κ°€μ΄λ“
- `EXECUTION_GUIDE.sh` - λ…λ Ήμ–΄ μμ 
- `adapter_training_example.py` - Python μμ 
