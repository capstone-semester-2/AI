"""


{
  "EmitterId": "user-123",   // (ì„ íƒ)
  "pairs": [
    {
      "audioUrl": "https://.../user123_01.wav",
      "text": "ë‚˜ëŠ” í•™êµì— ê°‘ë‹ˆë‹¤"
    },
    {
      "audioUrl": "https://.../user123_02.wav",
      "text": "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”"
    }
  ]
}



"""





# -- ìƒë‹¨ import ë¶€ --
import os, tempfile, hashlib, time, asyncio, re, logging, signal, shutil, subprocess
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse
import httpx
import torchaudio
from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel, HttpUrl
import uvicorn

from kospeech1.bin.inference import get_model, infer_on_file

# ---- ì„¤ì •ê°’ ----
MAX_BYTES = int(os.getenv("MAX_BYTES", 50 * 1024 * 1024))   # 50MB
MAX_SECONDS = int(os.getenv("MAX_SECONDS", 600))            # ìµœëŒ€ 10ë¶„ ì˜¤ë””ì˜¤
INFER_TIMEOUT_S = int(os.getenv("INFER_TIMEOUT_S", 120))    # ì¶”ë¡  íƒ€ì„ì•„ì›ƒ
CONCURRENCY = int(os.getenv("CONCURRENCY", 1))              # ë™ì‹œ ì²˜ë¦¬ ìˆ˜(=1ì´ë©´ â€œí•œ ë²ˆì— í•œ íŒŒì¼â€)
IDLE_SHUTDOWN_S = int(os.getenv("IDLE_SHUTDOWN_S", 60000))  # ìœ íœ´ ì¢…ë£Œ ì„ê³„
HTTP_TIMEOUT = httpx.Timeout(connect=5.0, read=30.0, write=10.0, pool=5.0)

# ì–´ëŒ‘í„° í•™ìŠµìš© ì¶”ê°€ ì„¤ì •
ADAPTER_TRAIN_TIMEOUT_S = int(os.getenv("ADAPTER_TRAIN_TIMEOUT_S", 1800))  # í•™ìŠµ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 30ë¶„)

# ë² ì´ìŠ¤ ëª¨ë¸ / ì–´ëŒ‘í„° ê²½ë¡œ (inference ëª¨ë“ˆê³¼ ë™ì¼ env ì‚¬ìš©)
BASE_MODEL_KOREAN = os.getenv("MODEL_PATH_1", "/home/ubuntu/model/model1.pt")
BASE_MODEL_HEARING = os.getenv("MODEL_PATH_2", "/home/ubuntu/model/model2.pt")
BASE_MODEL_NEURO = os.getenv("MODEL_PATH_3", "/home/ubuntu/model/model3.pt")

ADAPTER_PATH_HEARING = os.getenv("ADAPTER_PATH_2", "/home/ubuntu/model/adp2.pt")
ADAPTER_PATH_NEURO = os.getenv("ADAPTER_PATH_3", "/home/ubuntu/model/adp3.pt")

# adapter_train ì—ì„œ ì–´ëŒ‘í„° ì €ì¥ ë””ë ‰í† ë¦¬
ADAPTER_SAVE_DIR_HEARING = os.path.dirname(ADAPTER_PATH_HEARING)
ADAPTER_SAVE_DIR_NEURO = os.path.dirname(ADAPTER_PATH_NEURO)

# adapter_train ì—ì„œ ì‚¬ìš©í•  ì–´ëŒ‘í„° ì´ë¦„ (íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°)
ADAPTER_NAME_HEARING = os.path.splitext(os.path.basename(ADAPTER_PATH_HEARING))[0]
ADAPTER_NAME_NEURO = os.path.splitext(os.path.basename(ADAPTER_PATH_NEURO))[0]

app = FastAPI(title="AI Server")
log = logging.getLogger("ai")

# ---- ë™ì‹œì„± ì œì–´ ----
sem = asyncio.Semaphore(CONCURRENCY)        # ì „ì—­ ë™ì‹œ ì²˜ë¦¬ ì œí•œ
user_locks: dict[str, asyncio.Lock] = {}    # (ì„ íƒ) ì‚¬ìš©ì ë‹¨ì¼ ì²˜ë¦¬ìš©


def _get_user_lock(user_id: str) -> asyncio.Lock:
    if user_id not in user_locks:
        user_locks[user_id] = asyncio.Lock()
    return user_locks[user_id]


# ---- ìœ íœ´ ì¢…ë£Œ ì›Œì²˜ ----
_last_req_ts = time.time()


@app.middleware("http")
async def _touch_last_request(request: Request, call_next):
    # ë§¤ ìš”ì²­ë§ˆë‹¤ ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê° ê°±ì‹ 
    global _last_req_ts
    _last_req_ts = time.time()
    return await call_next(request)


async def _idle_watcher():
    """ë§ˆì§€ë§‰ ìš”ì²­ ì´í›„ IDLE_SHUTDOWN_S ì´ˆ ì§€ë‚˜ë©´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ(SIGTERM)."""
    global _last_req_ts
    try:
        while True:
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì ê²€
            if time.time() - _last_req_ts >= IDLE_SHUTDOWN_S:
                log.info(f"[idle] no requests for {IDLE_SHUTDOWN_S}s â†’ shutting down")
                os.kill(os.getpid(), signal.SIGTERM)  # uvicornì´ ìš°ì•„í•˜ê²Œ ì¢…ë£Œ
                return
    except asyncio.CancelledError:
        return


@app.on_event("startup")
async def _startup():
    # ëª¨ë¸ ì›œì—…
    get_model()
    app.state._idle_task = asyncio.create_task(_idle_watcher())
    log.info("model loaded (warm), idle watcher started")


@app.on_event("shutdown")
async def _shutdown():
    t = getattr(app.state, "_idle_task", None)
    if t:
        t.cancel()


@app.get("/api/health")
async def health():
    return {"ok": True}


# ==== ìš”ì²­ ìŠ¤í‚¤ë§ˆ ====

class AnalyzeReq(BaseModel):
    audioUrl: HttpUrl
    EmitterId: Optional[str] = None   # ë°±ì—”ë“œì—ì„œ ë„˜ê²¨ì£¼ëŠ” ì‹ë³„ì (ì˜µì…˜)


class TrainPair(BaseModel):
    audioUrl: HttpUrl
    text: str


class AdapterTrainReq(BaseModel):
    pairs: List[TrainPair]
    EmitterId: Optional[str] = None   # í•™ìŠµ ìš”ì²­ë„ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥ (ë½ í‚¤)


# ==== ê³µí†µ ìœ í‹¸ ====

async def _download_to_temp_file(url: str, suffix: str = ".wav") -> tuple[str, str, float]:
    """
    í•˜ë‚˜ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ì‹œ ê²½ë¡œë¡œ ë‹¤ìš´ë¡œë“œ.
    return: (tmp_path, sha256_hex, download_time_sec)
    """
    t0 = time.time()
    h = hashlib.sha256()
    tmp_path = None

    async with httpx.AsyncClient(timeout=HTTP_TIMEOUT, follow_redirects=True) as cli:
        head = await cli.head(str(url))
        cl = head.headers.get("Content-Length")
        if cl and int(cl) > MAX_BYTES:
            raise HTTPException(413, "File too large.")

        f = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        tmp_path = f.name

        async with cli.stream("GET", str(url)) as r:
            r.raise_for_status()
            n = 0
            async for chunk in r.aiter_bytes():
                n += len(chunk)
                if n > MAX_BYTES:
                    raise HTTPException(413, "File too large.")
                h.update(chunk)
                f.write(chunk)
        f.flush()

    t1 = time.time()

    # ê¸¸ì´ ì œí•œ ì²´í¬
    try:
        info = torchaudio.info(tmp_path)
        if info.num_frames and info.sample_rate:
            sec = info.num_frames / float(info.sample_rate)
            if sec > MAX_SECONDS:
                raise HTTPException(413, f"Audio too long: {sec:.1f}s > {MAX_SECONDS}s")
    except Exception:
        # info ì–»ê¸° ì‹¤íŒ¨í•´ë„ ì¶”ë¡ /í•™ìŠµì€ ì‹œë„
        pass

    return tmp_path, h.hexdigest(), (t1 - t0)


async def _handle_infer(req: AnalyzeReq, model_name: Optional[str] = None) -> Dict[str, Any]:
    """
    korean / hearing / neuro / hearing-adapter / neuro-adapter ê³µí†µ ì²˜ë¦¬ í•¨ìˆ˜.
    """
    t0 = time.time()
    print(f"[{model_name or 'korean'}] Audio URL: {req.audioUrl}")

    # ì‚¬ìš©ì ë‹¨ì¼ ì²˜ë¦¬(ì˜µì…˜) - EmitterId ê¸°ë°˜
    user_lock = _get_user_lock(req.EmitterId) if req.EmitterId else None

    # ì „ì—­ ë™ì‹œì„± ëŒ€ê¸°ì—´
    acquired_sem = False
    try:
        await asyncio.wait_for(sem.acquire(), timeout=5)
        acquired_sem = True
    except asyncio.TimeoutError:
        raise HTTPException(429, "busy, try again later")

    if user_lock:
        await user_lock.acquire()

    tmp_path = None

    try:
        # (1) ë‹¤ìš´ë¡œë“œ
        tmp_path, sha256_hex, dl_sec = await _download_to_temp_file(str(req.audioUrl), suffix=".wav")
        t1 = t0 + dl_sec

        # (2) ì¶”ë¡ (íƒ€ì„ì•„ì›ƒ)
        from functools import partial
        loop = asyncio.get_running_loop()
        infer_call = partial(infer_on_file, tmp_path, model_name=model_name)

        try:
            result = await asyncio.wait_for(
                loop.run_in_executor(None, infer_call),
                timeout=INFER_TIMEOUT_S,
            )
        except asyncio.TimeoutError:
            raise HTTPException(504, "Inference timeout")

        # (3) ì‘ë‹µ
        original_name = os.path.basename(urlparse(str(req.audioUrl)).path)
        result["title"] = original_name

        t2 = time.time()

        print(f"[{model_name or 'korean'}] result: {result}")

        out: Dict[str, Any] = {
            "sha256": sha256_hex,
            "downloadMs": int((t1 - t0) * 1000),
            "inferenceMs": int((t2 - t1) * 1000),
            "elapsedMs": int((t2 - t0) * 1000),
            "result": result,
        }

        # EmitterId ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ echo
        if req.EmitterId is not None:
            out["EmitterId"] = req.EmitterId

        return out

    finally:
        if tmp_path:
            try:
                os.remove(tmp_path)
            except Exception:
                pass

        if user_lock and user_lock.locked():
            user_lock.release()

        if acquired_sem:
            sem.release()


def _run_adapter_train_subprocess(
    base_model_path: str,
    adapter_save_dir: str,
    adapter_name: str,
    dataset_dir: str,
    transcripts_path: str,
    extra_override: Optional[str] = None,
):
    """
    kospeech1/bin/main.py ì˜ Hydra ì—”íŠ¸ë¦¬(train=adapter_train)ë¥¼ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ í˜¸ì¶œ.
    - num_epochs ëŠ” 50 ìœ¼ë¡œ ê³ ì •.
    """
    cmd = [
        "python",
        "./kospeech1/bin/main.py",
        "model=ds2",
        "train=adapter_train",
        f"train.dataset_path={dataset_dir}",
        f"train.transcripts_path={transcripts_path}",
        f"train.base_model_path={base_model_path}",
        f"train.adapter_name={adapter_name}",
        "train.batch_size=3",
        "train.num_epochs=50",                 # ğŸ”¥ ì—í¬í¬ 50 ê³ ì •
        f"train.adapter_save_dir={adapter_save_dir}",
        "train.adapter_hidden_dims=[512,256]", # í•„ìš”ì‹œ ì¡°ì • ê°€ëŠ¥
    ]
    if extra_override:
        cmd.append(extra_override)

    print("[adapter-train] run:", " ".join(cmd))
    # í•™ìŠµ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒì‹œí‚¤ë„ë¡ check=True
    subprocess.run(cmd, check=True)


async def _handle_adapter_train(
    req: AdapterTrainReq,
    base_model_path: str,
    adapter_save_dir: str,
    adapter_name: str,
) -> Dict[str, Any]:
    """
    hearing-adapter-train / neuro-adapter-train ê³µí†µ ì²˜ë¦¬ í•¨ìˆ˜.
    - req.pairs: [{audioUrl, text}, ...]
    """
    if not req.pairs:
        raise HTTPException(400, "pairs must not be empty")

    t0 = time.time()
    user_lock = _get_user_lock(req.EmitterId) if req.EmitterId else None

    # ì „ì—­ ë™ì‹œì„±
    acquired_sem = False
    try:
        await asyncio.wait_for(sem.acquire(), timeout=5)
        acquired_sem = True
    except asyncio.TimeoutError:
        raise HTTPException(429, "busy, try again later")

    if user_lock:
        await user_lock.acquire()

    tmp_root = None
    download_infos = []

    try:
        # (1) ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        tmp_root = tempfile.mkdtemp(prefix="adapter_train_")
        audio_dir = tmp_root  # wav ë“¤ì„ ì—¬ê¸°ì— ì €ì¥
        transcripts_path = os.path.join(tmp_root, "transcripts.txt")

        # (2) pairs ë°˜ë³µí•˜ë©° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ + transcripts ì‘ì„± ì¤€ë¹„
        # transcripts í˜•ì‹: "<íŒŒì¼ëª…>\t<ì •ë‹µ í…ìŠ¤íŠ¸>\n"
        with open(transcripts_path, "w", encoding="utf-8") as tf:
            for idx, pair in enumerate(req.pairs):
                url = str(pair.audioUrl)
                # íŒŒì¼ ì´ë¦„: sample_0001.wav ì´ëŸ° ì‹
                fname = f"sample_{idx+1:04d}.wav"
                local_path = os.path.join(audio_dir, fname)

                # ê° íŒŒì¼ ë³„ë¡œ ë‹¤ìš´ë¡œë“œ
                tmp_path, sha_hex, dl_sec = await _download_to_temp_file(url, suffix=".wav")
                # tmp_path -> local_path ë¡œ ì´ë™
                shutil.move(tmp_path, local_path)

                download_infos.append({
                    "url": url,
                    "local_path": local_path,
                    "sha256": sha_hex,
                    "download_sec": dl_sec,
                })

                # transcripts ì— ìƒëŒ€ ê²½ë¡œ(ë˜ëŠ” íŒŒì¼ëª…) ê¸°ë¡
                tf.write(f"{fname}\t{pair.text.strip()}\n")

        t1 = time.time()

        # (3) ì„œë¸Œí”„ë¡œì„¸ìŠ¤ì—ì„œ adapter_train ì‹¤í–‰
        loop = asyncio.get_running_loop()
        train_call = lambda: _run_adapter_train_subprocess(
            base_model_path=base_model_path,
            adapter_save_dir=adapter_save_dir,
            adapter_name=adapter_name,
            dataset_dir=audio_dir,
            transcripts_path=transcripts_path,
        )

        try:
            await asyncio.wait_for(
                loop.run_in_executor(None, train_call),
                timeout=ADAPTER_TRAIN_TIMEOUT_S,
            )
        except asyncio.TimeoutError:
            raise HTTPException(504, "Adapter training timeout")
        except subprocess.CalledProcessError as e:
            # í•™ìŠµ ì‹¤íŒ¨
            raise HTTPException(500, f"Adapter training failed: {e}") from e

        t2 = time.time()

        # (4) ì‘ë‹µ êµ¬ì„±
        out: Dict[str, Any] = {
            "ok": True,
            "adapterName": adapter_name,
            "adapterSaveDir": adapter_save_dir,
            "numPairs": len(req.pairs),
            "downloadMs": int((t1 - t0) * 1000),
            "trainMs": int((t2 - t1) * 1000),
            "elapsedMs": int((t2 - t0) * 1000),
        }
        if req.EmitterId is not None:
            out["EmitterId"] = req.EmitterId

        return out

    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        if tmp_root and os.path.isdir(tmp_root):
            try:
                shutil.rmtree(tmp_root)
            except Exception:
                pass

        if user_lock and user_lock.locked():
            user_lock.release()

        if acquired_sem:
            sem.release()


# ==== ì¸í¼ëŸ°ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ ====

@app.post("/api/korean")
async def korean(req: AnalyzeReq):
    # ê¸°ë³¸ ëª¨ë¸ (inference ëª¨ë“ˆì˜ DEFAULT_MODEL_NAME = "korean")
    return await _handle_infer(req, model_name="korean")


@app.post("/api/hearing")
async def hearing(req: AnalyzeReq):
    # ëª¨ë¸2 (ì–´ëŒ‘í„° ì—†ëŠ” ë²„ì „)
    return await _handle_infer(req, model_name="hearing")


@app.post("/api/neuro")
async def neuro(req: AnalyzeReq):
    # ëª¨ë¸3 (ì–´ëŒ‘í„° ì—†ëŠ” ë²„ì „)
    return await _handle_infer(req, model_name="neuro")


@app.post("/api/hearing-adapter")
async def hearing_adapter(req: AnalyzeReq):
    # ëª¨ë¸2 + hearing adapter
    return await _handle_infer(req, model_name="hearing_adapter")


@app.post("/api/neuro-adapter")
async def neuro_adapter(req: AnalyzeReq):
    # ëª¨ë¸3 + neuro adapter
    return await _handle_infer(req, model_name="neuro_adapter")


# ==== ì–´ëŒ‘í„° í•™ìŠµ ì—”ë“œí¬ì¸íŠ¸ ====

@app.post("/api/hearing-adapter-train")
async def hearing_adapter_train(req: AdapterTrainReq):
    """
    ëª¨ë¸2(hearing ë² ì´ìŠ¤)ì— ë¶™ì¼ ì–´ëŒ‘í„°ë¥¼ í•™ìŠµ.
    ìš”ì²­ JSON ì•ˆì˜ pairs ì— (audioUrl + text)ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.
    """
    if not BASE_MODEL_HEARING:
        raise HTTPException(500, "MODEL_PATH_2 (hearing base) is not set")

    if not ADAPTER_SAVE_DIR_HEARING:
        raise HTTPException(500, "ADAPTER_PATH_2 / ADAPTER_SAVE_DIR_HEARING not set")

    return await _handle_adapter_train(
        req=req,
        base_model_path=BASE_MODEL_HEARING,
        adapter_save_dir=ADAPTER_SAVE_DIR_HEARING,
        adapter_name=ADAPTER_NAME_HEARING,
    )


@app.post("/api/neuro-adapter-train")
async def neuro_adapter_train(req: AdapterTrainReq):
    """
    ëª¨ë¸3(neuro ë² ì´ìŠ¤)ì— ë¶™ì¼ ì–´ëŒ‘í„°ë¥¼ í•™ìŠµ.
    ìš”ì²­ JSON ì•ˆì˜ pairs ì— (audioUrl + text)ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.
    """
    if not BASE_MODEL_NEURO:
        raise HTTPException(500, "MODEL_PATH_3 (neuro base) is not set")

    if not ADAPTER_SAVE_DIR_NEURO:
        raise HTTPException(500, "ADAPTER_PATH_3 / ADAPTER_SAVE_DIR_NEURO not set")

    return await _handle_adapter_train(
        req=req,
        base_model_path=BASE_MODEL_NEURO,
        adapter_save_dir=ADAPTER_SAVE_DIR_NEURO,
        adapter_name=ADAPTER_NAME_NEURO,
    )


# ----(ì°¸ê³ ) uvicorn ì‹¤í–‰ ì˜ˆì‹œ----
# uvicorn kospeech1.server:app --host 0.0.0.0 --port 8000
